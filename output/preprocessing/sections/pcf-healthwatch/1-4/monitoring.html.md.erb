---
title: Monitoring PCF Healthwatch
owner: PCF Healthwatch
warning: This file is auto-generated by code.cloudfoundry.org/indicators. Any changes will likely be overwritten. Edit the associated indicators yaml file to make changes.
---

<p>This topic explains how to monitor the health of Pivotal Cloud Foundry (PCF) Healthwatch using the metrics and key performance indicators (KPIs) generated by the service.</p>

<p>For general information about monitoring PCF, see <a href="https://docs.pivotal.io/pivotalcf/monitoring/index.html">Monitoring Pivotal Cloud Foundry</a>.</p>



## <a id="about-metrics"></a>About Metrics
<p>PCF Healthwatch emits metrics in the following format:</p>

<pre><code>origin:&quot;healthwatch&quot; eventType:ValueMetric timestamp:1509638101820496694 deployment:&quot;healthwatch-app-dev-v1-3&quot;
job:&quot;healthwatch-forwarder&quot; index:&quot;097f4b1e-5ca8-4866-82d5-00883798dad4&quot; ip:&quot;10.0.16.29&quot; 
valueMetric:&lt;name:&quot;metrics.published&quot; value:38 unit:&quot;count&quot;&gt;
</code></pre>

<p>All PCF Healthwatch-emitted metrics have the <code>healthwatch</code> origin.</p>



## <a id="service-level-indicators-for-pcf-healthwatch"></a>Service Level Indicators for PCF Healthwatch
<p>Service Level Indicators monitor that key features of the PCF Healthwatch product are working as expected. These SLIs are the most important operational metrics emitted about Healthwatch itself, as they indicate the reliability of the assessments Healthwatch is making.</p>



### <a id="cf_cli_probe_availability_percentage"></a>CLI Health Test Availability
<table>
    <tr>
        <th width="25%">Description</th>
        <td><p><strong>Use</strong>: Indicates that PCF Healthwatch is assessing the health of the Cloud Foundry Command Line Interface (cf CLI) commands. If these continuous validation tests fail to make up-to-date assessments, they are no longer a reliable warning mechanism.</p>

<p><strong>Metrics</strong>:
  name: health.check.cliCommand.probe.available
  source_id: healthwatch-forwarder</p>
</td>
    </tr>
    <tr>
        <th>PromQL</th>
        <td>
			<code>avg_over_time(health_check_cliCommand_probe_available{source_id="healthwatch-forwarder",deployment="$deployment"}[5m])</code>
		</td>
    </tr>
    <tr>
		
        <th>Thresholds</th>
        <td>
             <em>Yellow warning</em>: &lt;= 0.6<br/>  <em>Red critical</em>: &lt;= 0.4<br/> 
			      
			      	<p>These are environment specific</p>

        </td>
    </tr>
	
    	<tr>
    	    <th>Measurement</th>
    	    <td>
    	        <p>Average over last 5 minutes</p>

    	    </td>
    	</tr>
    	<tr>
    	    <th>Recommended Response</th>
    	    <td>
    	        <ol>
<li>Ensure the <code>cf-health-check</code> app is running in the <code>healthwatch</code> space of the <code>system</code> org.</li>
<li>Check the app logs for any obvious errors.</li>
</ol>

    	    </td>
    	</tr>
</table>
### <a id="canary_app_probe_availability_percentage"></a>Canary App Health Test Availability
<table>
    <tr>
        <th width="25%">Description</th>
        <td><p><strong>Use</strong>: Indicates that PCF Healthwatch is assessing the current state of health for the canary app. If this continuous validation test fails to make up-to-date assessments, it is no longer a reliable warning mechanism.</p>

<p><strong>Metrics</strong>:
  name: health.check.CanaryApp.probe.available
  source_id: healthwatch-forwarder</p>
</td>
    </tr>
    <tr>
        <th>PromQL</th>
        <td>
			<code>avg_over_time(health_check_CanaryApp_probe_available{source_id="healthwatch-forwarder",deployment="$deployment"}[5m])</code>
		</td>
    </tr>
    <tr>
		
        <th>Thresholds</th>
        <td>
             <em>Yellow warning</em>: &lt;= 0.6<br/>  <em>Red critical</em>: &lt;= 0.4<br/> 
			      
			      	<p>These are environment specific</p>

        </td>
    </tr>
	
    	<tr>
    	    <th>Measurement</th>
    	    <td>
    	        <p>Average over last 5 minutes</p>

    	    </td>
    	</tr>
    	<tr>
    	    <th>Recommended Response</th>
    	    <td>
    	        <ol>
<li>Ensure the <code>canary-health-check</code> app is running in the <code>healthwatch</code> space of the <code>system</code> org. Check the app logs for any obvious errors.</li>
<li>Verify that Apps Manager is running and accessible through the URL configured in the <code>CANARY_URL</code> environment variable of the <code>canary-health-check</code> app.</li>
</ol>

    	    </td>
    	</tr>
</table>
### <a id="bosh_director_probe_availability_percentage"></a>BOSH Director Health Test Availability
<table>
    <tr>
        <th width="25%">Description</th>
        <td><p><strong>Use</strong>: Indicates that PCF Healthwatch is assessing the current state of health for the BOSH Director. If this continuous validation test fails to make up-to-date assessments, it is no longer a reliable warning mechanism.</p>

<p><strong>Metrics</strong>:
  name: health.check.bosh.director.probe.available
  source_id: healthwatch-forwarder</p>
</td>
    </tr>
    <tr>
        <th>PromQL</th>
        <td>
			<code>avg_over_time(health_check_bosh_director_probe_available{source_id="healthwatch-forwarder",deployment="$deployment"}[5m])</code>
		</td>
    </tr>
    <tr>
		
        <th>Thresholds</th>
        <td>
             <em>Yellow warning</em>: &lt;= 0.6<br/>  <em>Red critical</em>: &lt;= 0.4<br/> 
			      
			      	<p>These are environment specific</p>

        </td>
    </tr>
	
    	<tr>
    	    <th>Measurement</th>
    	    <td>
    	        <p>Average over last 5 minutes</p>

    	    </td>
    	</tr>
    	<tr>
    	    <th>Recommended Response</th>
    	    <td>
    	        <ol>
<li>Ensure the <code>bosh-health-check</code> app is running in the <code>healthwatch</code> space of the <code>system</code> org. Check the app logs for any obvious errors.</li>
<li>SSH into the running <code>bosh-health-check</code> app and copy the BOSH manifest from <code>/home/vcap/app/health_check_manifest.yml</code>. Try to deploy it manually on the BOSH Director and check for errors.</li>
</ol>

    	    </td>
    	</tr>
</table>
### <a id="ops_man_probe_availability_percentage"></a>Ops Manager Health Test Availability
<table>
    <tr>
        <th width="25%">Description</th>
        <td><p><strong>Use</strong>: Indicates that PCF Healthwatch is assessing the current state of health for Ops Manager. If this continuous validation test fails to make up-to-date assessments, it is no longer a reliable warning mechanism.</p>

<p><strong>Metrics</strong>:
  name: health.check.OpsMan.probe.available
  source_id: healthwatch-forwarder</p>
</td>
    </tr>
    <tr>
        <th>PromQL</th>
        <td>
			<code>avg_over_time(health_check_OpsMan_probe_available{source_id="healthwatch-forwarder",deployment="$deployment"}[5m])</code>
		</td>
    </tr>
    <tr>
		
        <th>Thresholds</th>
        <td>
             <em>Yellow warning</em>: &lt;= 0.6<br/>  <em>Red critical</em>: &lt;= 0.4<br/> 
			      
			      	<p>These are environment specific</p>

        </td>
    </tr>
	
    	<tr>
    	    <th>Measurement</th>
    	    <td>
    	        <p>Average over last 5 minutes</p>

    	    </td>
    	</tr>
    	<tr>
    	    <th>Recommended Response</th>
    	    <td>
    	        <ol>
<li>Ensure the <code>opsmanager-health-check</code> app is running in the <code>healthwatch</code> space of the <code>system</code> org. Check the app logs for any obvious errors.</li>
<li>Verify that Ops Manager is running and accessible through the URL configured in the <code>OPSMANAGER_URL</code> environment variable of the <code>opsmanager-health-check</code> app.</li>
</ol>

    	    </td>
    	</tr>
</table>
### <a id="ui_availability_percentage"></a>PCF Healthwatch UI Availability
<table>
    <tr>
        <th width="25%">Description</th>
        <td><p><strong>Use</strong>: Indicates that the Healthwatch UI is running and available to product users. While an issue with the UI
does not impact the assessments that PCF Healthwatch is making, loss of the UI can impact user ability to visually
reference these assessments.</p>

<p><strong>Metrics</strong>:
  name: healthwatch.ui.available
  source_id: healthwatch-forwarder</p>
</td>
    </tr>
    <tr>
        <th>PromQL</th>
        <td>
			<code>avg_over_time(healthwatch_ui_available{source_id="healthwatch-forwarder",deployment="$deployment"}[5m])</code>
		</td>
    </tr>
    <tr>
		
        <th>Thresholds</th>
        <td>
             <em>Yellow warning</em>: &lt;= 0.6<br/>  <em>Red critical</em>: &lt;= 0.4<br/> 
			      
			      	<p>These are environment specific</p>

        </td>
    </tr>
	
    	<tr>
    	    <th>Measurement</th>
    	    <td>
    	        <p>Average over last 5 minutes</p>

    	    </td>
    	</tr>
    	<tr>
    	    <th>Recommended Response</th>
    	    <td>
    	        <ol>
<li>Ensure the <code>healthwatch</code> app is running in the healthwatch space of the system org.</li>
<li>Check the app logs for any obvious errors.</li>
<li>Verify that the <code>/info</code> endpoint is available on the healthwatch app route.</li>
</ol>

    	    </td>
    	</tr>
</table>
## <a id="key-performance-indicators-for-pcf-healthwatch"></a>Key Performance Indicators for PCF Healthwatch
<p>This section describes the KPIs that you can use to monitor the health of PCF Healthwatch.</p>



### <a id="nozzle_disconnects_per_instance"></a>Number of PCF Healthwatch Nozzle Disconnects from Firehose
<table>
    <tr>
        <th width="25%">Description</th>
        <td><p><strong>Use</strong>: An unusual increase in the number of disconnects from the Firehose typically indicates that you need to
scale the nozzle up. The Firehose disconnects nozzles that are slow consumers to protect apps from backpressure.
This metric can also spike during a PCF deployment because the Traffic Controller VMs restart, logging a disconnect.</p>

<p>A prolonged period of losing metrics as a result of disconnects can endanger the assessments that PCF Healthwatch
makes using platform metrics from the Firehose.</p>

<p><strong>Metrics</strong>:
  name: ingestor.disconnects
  source_id: healthwatch-forwarder</p>
</td>
    </tr>
    <tr>
        <th>PromQL</th>
        <td>
			<code>avg_over_time(ingestor_disconnects{source_id="healthwatch-forwarder",deployment="$deployment"}[5m])</code>
		</td>
    </tr>
    <tr>
		
        <th>Thresholds</th>
        <td>
             <em>Yellow warning</em>: &gt;= 20<br/>  <em>Red critical</em>: &gt;= 30<br/> 
			      
			      	<p>These are environment specific</p>

        </td>
    </tr>
	
    	<tr>
    	    <th>Measurement</th>
    	    <td>
    	        <p>Average over last 5 minutes</p>

    	    </td>
    	</tr>
    	<tr>
    	    <th>Recommended Response</th>
    	    <td>
    	        <p>If no known deployment occurred and the spike is sustained, increase the number of PCF Healthwatch Ingestor
instances and monitor this metric to ensure that it returns to a normal state.</p>

<p>You can scale Ingestor instances in the Healthwatch Component Config tab of the PCF Healthwatch tile or using the
<code>cf scale healthwatch-ingestor</code> command. While <code>cf scale</code> helps you to quickly scale the instances, you should also
update the tile configuration so that the next deployment does not override the manual scaling.</p>

    	    </td>
    	</tr>
</table>
### <a id="ingestor_dropped_metrics_per_instance"></a>Number of Ingestor Dropped Metrics
<table>
    <tr>
        <th width="25%">Description</th>
        <td><p><strong>Use</strong>: An unusual increase in the number of dropped messages by the PCF Healthwatch Ingestor likely indicates
that you need to scale up this component and verify the health of Redis. A prolonged period of dropping messages
can endanger the assessments that PCF Healthwatch makes using platform metrics from the Firehose.</p>

<p><strong>Metrics</strong>:
  name: ingestor.dropped
  source_id: healthwatch-forwarder</p>
</td>
    </tr>
    <tr>
        <th>PromQL</th>
        <td>
			<code>avg_over_time(ingestor_dropped{source_id="healthwatch-forwarder",deployment="$deployment"}[5m])</code>
		</td>
    </tr>
    <tr>
		
        <th>Thresholds</th>
        <td>
             <em>Yellow warning</em>: &gt;= 10<br/>  <em>Red critical</em>: &gt;= 20<br/> 
			      
			      	<p>These are environment specific</p>

        </td>
    </tr>
	
    	<tr>
    	    <th>Measurement</th>
    	    <td>
    	        <p>Average over last 5 minutes</p>

    	    </td>
    	</tr>
    	<tr>
    	    <th>Recommended Response</th>
    	    <td>
    	        <p>Verify the health of the Redis VM and increase the number of PCF Healthwatch Ingestor instances. Monitor this
metric to ensure that it returns to a normal state.</p>

<p>You can scale Ingestor instances using the <code>cf scale healthwatch-ingestor</code> command. While <code>cf scale</code> helps you to
quickly scale the instances, you should also update the Ingestor Count in the tile configuration located in
Healthwatch Component Config tab. Otherwise, the next <code>Apply Changes</code> will override the manual scaling.</p>

    	    </td>
    	</tr>
</table>
### <a id="redis_queue_size"></a>Redis Queue Size
<table>
    <tr>
        <th width="25%">Description</th>
        <td><p><strong>Use</strong>: An unusual spike in the number of queued metrics can indicate that PCF Healthwatch Workers are unable to
keep up with the volume of metrics from the Firehose. A large Redis queue will result in value metrics and counter
events being delayed; if the queue becomes completely full, metrics will be lost altogether. This will also
adversely affect PCF Healthwatch’s ability to calculate super value metrics.</p>

<p><strong>Metrics</strong>:
  name: redis.valueMetricQueue.size
  source_id: healthwatch-forwarder
  name: redis.counterEventQueue.size
  source_id: healthwatch-forwarder</p>
</td>
    </tr>
    <tr>
        <th>PromQL</th>
        <td>
			<code>redis_valueMetricQueue_size{source_id="healthwatch-forwarder",deployment="$deployment"} + redis_counterEventQueue_size{source_id="healthwatch-forwarder",deployment="$deployment"}</code>
		</td>
    </tr>
    <tr>
		
        <th>Thresholds</th>
        <td>
             <em>Red critical</em>: &gt;= 10000<br/> 
			      
        </td>
    </tr>
	
    	<tr>
    	    <th>Measurement</th>
    	    <td>
    	        <p>Average over last 5 minutes</p>

    	    </td>
    	</tr>
    	<tr>
    	    <th>Recommended Response</th>
    	    <td>
    	        <p>If the spike is sustained, increase the number of PCF Healthwatch Worker instances and monitor this metric to ensure
that it returns to a normal state.</p>

<p>You can scale Worker instances in the Healthwatch Component Config tab of the PCF Healthwatch tile or using the
<code>cf scale healthwatch-worker</code> command. While <code>cf scale</code> helps you to quickly scale the instances, you should also
update the tile configuration so that the next deployment does not override the manual scaling.</p>

    	    </td>
    	</tr>
</table>
### <a id="healthwatch_metrics_published_rate"></a>Number of Healthwatch Super Metrics Published to Firehose
<table>
    <tr>
        <th width="25%">Description</th>
        <td><p><strong>Use</strong>: If an operator has not made changes that impact the number or frequency of assessments, an unusual drop in the number of metrics published can indicate that PCF Healthwatch may be experiencing a computation or publication issue.</p>

<p><strong>Metrics</strong>:
  name: metrics.published
  source_id: healthwatch-forwarder</p>
</td>
    </tr>
    <tr>
        <th>PromQL</th>
        <td>
			<code>rate(metrics_published{source_id="healthwatch-forwarder",deployment="$deployment"}[5m])</code>
		</td>
    </tr>
    <tr>
		
        <th>Thresholds</th>
        <td>
             <em>Yellow warning</em>: &lt;= 20<br/>  <em>Red critical</em>: &lt;= 10<br/> 
			      
			      	<p>These are environment specific</p>

        </td>
    </tr>
	
    	<tr>
    	    <th>Measurement</th>
    	    <td>
    	        <p>Average over last 5 minutes</p>

    	    </td>
    	</tr>
    	<tr>
    	    <th>Recommended Response</th>
    	    <td>
    	        <ol>
<li>Verify that the <code>healthwatch-forwarder</code> VM is running.</li>
<li>Check all of the logs in <code>/var/vcap/sys/log</code> on the VM.</li>
<li>Verify that the <code>*-health-check</code> apps are running and the logs in the <code>healthwatch</code> space of the <code>system</code> org are not receiving any obvious errors from them.</li>
</ol>

    	    </td>
    	</tr>
</table>
## <a id="other-metrics-available"></a>Other Metrics Available
<p>This section describes other metrics that you can use to monitor PCF Healthwatch.</p>



### <a id="events_published"></a>Number of Healthwatch Events Published to PCF Event Alerts
<table>
    <tr>
        <th width="25%">Description</th>
        <td><p>Number of PCF Healthwatch Event Alerts triggered and published to
[PCF Event Alerts](<a href="http://docs.pivotal.io/event-alerts/index.html">http://docs.pivotal.io/event-alerts/index.html</a>.</p>

<p><strong>Use</strong>: This metric is primarily interesting for informational purposes. As the number of alerting events could
vary greatly, it is not recommended to alert on this metric itself.</p>
</td>
    </tr>
    <tr>
        <th>PromQL</th>
        <td>
			<code>events_published{source_id="healthwatch-forwarder",deployment="$deployment"}</code>
		</td>
    </tr>
    <tr>
		
    </tr>
	
</table>
### <a id="health_bosh_deployment_probe_count"></a>BOSH Deployment Check Probe
<table>
    <tr>
        <th width="25%">Description</th>
        <td><p>Number of PCF Healthwatch <a href="http://docs.pivotal.io/pcf-healthwatch/1-2/metrics.html#bosh-deployment">BOSH Deployment Occurrence</a>
probes completed in the measured time interval.</p>

<p><strong>Use</strong>: When monitoring this metric, the primary indicator of concern is an unexpected negative variance from the
normal pattern of checks per test type. If an operator has not made changes that impact the number of checks being
made, such as scaling the test runner or changing the frequency of the test, an unexpected variance from normal
likely indicates problems in the test runner functionality.</p>

<p>In the default installation, these tests run every 30 seconds across 2 runner apps.</p>
</td>
    </tr>
    <tr>
        <th>PromQL</th>
        <td>
			<code>health_bosh_deployment_probe_count{source_id="healthwatch-forwarder",deployment="$deployment"}</code>
		</td>
    </tr>
    <tr>
		
    </tr>
	
</table>
### <a id="health_check_cliCommand_probe_count"></a>CLI Command Health
<table>
    <tr>
        <th width="25%">Description</th>
        <td><p>Number of PCF Healthwatch <a href="metrics.html#cli">CLI Command Health</a> probe assessments completed in the measured time interval.</p>

<p><strong>Use</strong>: For alerting purposes, Pivotal suggests using <code>health.check.cliCommand.probe.available</code> instead. This metric is most helpful for additional diagnostics or secondary alerting.</p>

<p>When monitoring this metric, the primary indicator of concern is an unexpected negative variance from the normal pattern of checks per test type. If an operator has not made changes that impact the number of checks being made, such as scaling the test runner or changing the frequency of the test, an unexpected variance from normal likely indicates problems in the test runner functionality.</p>

<p>In the default installation, these tests run every 5 minutes across 2 runner apps.</p>
</td>
    </tr>
    <tr>
        <th>PromQL</th>
        <td>
			<code>health_check_cliCommand_probe_count{source_id="healthwatch-forwarder",deployment="$deployment"}</code>
		</td>
    </tr>
    <tr>
		
    </tr>
	
</table>
### <a id="health_check_OpsMan_probe_count"></a>Ops Manager Health
<table>
    <tr>
        <th width="25%">Description</th>
        <td><p>Number of PCF Healthwatch <a href="metrics.html#opsman">Ops Manager Health</a> probe assessments completed in the measured time interval.</p>

<p><strong>Use</strong>: For alerting purposes, Pivotal suggests using <code>health.check.OpsMan.probe.available</code> instead. This metric is most helpful for additional diagnostics or secondary alerting.</p>

<p>When monitoring this metric, the primary indicator of concern is an unexpected negative variance from the normal pattern of checks per test type. If an operator has not made changes that impact the number of checks being made, such as scaling the test runner or changing the frequency of the test, an unexpected variance from normal likely indicates problems in the test runner functionality.</p>

<p>In the default installation, these tests run every 1 minute across 2 runner apps.</p>
</td>
    </tr>
    <tr>
        <th>PromQL</th>
        <td>
			<code>health_check_OpsMan_probe_count{source_id="healthwatch-forwarder",deployment="$deployment"}</code>
		</td>
    </tr>
    <tr>
		
    </tr>
	
</table>
### <a id="health_check_CanaryApp_probe_count"></a>Canary App Health
<table>
    <tr>
        <th width="25%">Description</th>
        <td><p>Number of PCF Healthwatch <a href="metrics.html#canaryapp">Canary App Health</a> probe assessments completed in the measured time interval.</p>

<p><strong>Use</strong>: For alerting purposes, Pivotal suggests using <code>health.check.CanaryApp.probe.available</code> instead. This metric is most helpful for additional diagnostics or secondary alerting.</p>

<p>When monitoring this metric, the primary indicator of concern is an unexpected negative variance from the normal pattern of checks per test type. If an operator has not made changes that impact the number of checks being made, such as scaling the test runner or changing the frequency of the test, an unexpected variance from normal likely indicates problems in the test runner functionality.</p>

<p>In the default installation, these tests run every 1 minutes across 2 runner apps.</p>
</td>
    </tr>
    <tr>
        <th>PromQL</th>
        <td>
			<code>health_check_CanaryApp_probe_count{source_id="healthwatch-forwarder",deployment="$deployment"}</code>
		</td>
    </tr>
    <tr>
		
    </tr>
	
</table>
### <a id="health_check_bosh_director_probe_count"></a>BOSH Director Health
<table>
    <tr>
        <th width="25%">Description</th>
        <td><p>Number of PCF Healthwatch <a href="metrics.html#bosh-director">BOSH Director Health</a> probe assessments completed in the measured time interval.</p>

<p><strong>Use</strong>: For alerting purposes, Pivotal suggests using <code>health.check.bosh.director.probe.available</code> instead. This metric is most helpful for additional diagnostics or secondary alerting.</p>

<p>When monitoring this metric, the primary indicator of concern is an unexpected negative variance from the normal pattern of checks per test type. If an operator has not made changes that impact the number of checks being made, such as scaling the test runner or changing the frequency of the test, an unexpected variance from normal likely indicates problems in the test runner functionality.</p>

<p>In the default installation, these tests run every 10 minutes using 1 runner app.</p>
</td>
    </tr>
    <tr>
        <th>PromQL</th>
        <td>
			<code>health_check_bosh_director_probe_count{source_id="healthwatch-forwarder",deployment="$deployment"}</code>
		</td>
    </tr>
    <tr>
		
    </tr>
	
</table>
